Five nines mean that systems and services are available 99.999% of the time. It also means that both planned and unplanned downtime is less than 5.26 minutes per year.
High availability refers to a system or component that is continuously operational for a given length of time. To help ensure high availability;
Eliminate single points of failure
Design for reliability
Detect failures as they occur.
Sustaining high availability at the standard of five-nines can increase costs and utilize many resources. The increased costs are due to the purchase of additional hardware such as servers and components.
Environments that Require Five Nines:
The finance industry needs to maintain high availability for continuous trading, compliance, and customer trust.
Healthcare facilities require high availability to provide around-the-clock care for patients.
The public safety industry includes agencies that provide security and services to a community, state, or nation.
The retail industry depends on efficient supply chains and the delivery of products to customers. Disruption can be devastating, especially during peak demand times such as holidays.
The public expects that the news media industry communicate information on events as they happen. The news cycle is now around the clock, 24/7.
Threat To Availability: The following threats pose a high risk to data and information availability;
Natural Disasters: A severe storm such as a hurricane, tornado, earthquake, floods or fires.
Human Error: Employee makes inadvertent data entry errors, drop laptop computer, compromise of the Admin or root user occurs.
Hardware Failures: Hard drive crashes, firewall misconfiguration.
Sabotage: Attacker installs backdoor or worm that erase files.
Software Attacks: An unauthorized user successfully penetrates and compromises an organization’s primary database through viruses, worms, or DoS attacks.
Software Errors: Software bug prevents program from properly loading.
Theft: Laptops or equipment stolen from unlocked room.
Utility Interruption: Electrical power failure.
Designing High Availability System: High availability incorporates three major principles to achieve the goal of uninterrupted access to data and services and they are;
Elimination or Reduction of Single-Points of Failure: The point in a critical operation that causes the entire operation to fail should it fail and it includes central routers or switches, network services, and even highly skilled IT staff. The key is to have processes, resources, and components that reduce single points of failure. High availability clusters is one way to provide redundancy. These clusters consist of a group of computers that have access to the same-shared storage and have identical network configurations. All servers take part in processing a service simultaneously. From the outside, the server group looks like one device. If a server within the cluster fails, the other servers continue to process the same service as the failed device.
System Resiliency: Systems resiliency refers to the capability to maintain availability of data and operational processing despite attacks or disrupting event. Generally, this requires redundant systems, in terms of both power and processing, so that should one system fail, the other can take over operations without any break in service. System resiliency is more than hardening devices; it requires that both data and services be available even when under attack.
Fault Tolerance: Fault tolerance enables a system to continue to operate if one or more components fail. Data mirroring is one example of fault tolerance. Should a "fault" occur, causing disruption in a device such as a disk controller, the mirrored system provides the requested data with no apparent interruption in service to the user. 
Asset Identification/Management: Asset management includes a complete inventory of hardware and software. Organization need to know all components that can be subject to security risks and they include; Every hardware system, operating system, hardware network device, network device operating system, software application, All firmware, language runtime environments, individual libraries. An organization may choose an automated solution to keep track of assets.
Asset Classification:Asset classification assigns all resources of an organization into a group based on common characteristics. The most critical information needs to receive the highest level of protection and may even require special handling.
Asset Standardization: Asset standards identify specific hardware and software products that the organization uses and supports.  If an organization does not standardize its hardware selection, personnel may need to scramble to find a replacement component. Non-standard environments require more expertise to manage and they increase the cost of maintenance contracts and inventory. 
Threat Identification begins with the process of creating a Common Vulnerability and Exposure(CVE) Identifier for publicly known cybersecurity vulnerabilities. CVE contains a standard identifier number with a brief description, and references to related vulnerability reports and advisories. The CVE list and its public website is maintained by MITRE corporation.
Risk Analysis: Risk analysis is the process of analyzing the dangers posed by natural and human-caused events to the assets of an organization. A risk analysis has four goals and they are;
Identify assets and their value
Identify vulnerabilities and threats
Quantify the probability and impact of the identified threats
Balance the impact of the threat against the cost of the countermeasure.
There are two approaches to Risk Analysis and they are;
Quantitative Risk Analysis: A quantitative analysis assigns numbers to the risk analysis process.
Qualitative Risk Analysis: Qualitative Risk Analysis uses opinions and scenarios.
Mitigation involves reducing the severity of the loss or the likelihood of the loss from occurring.  Risk mitigation can have both positive and negative impact on the organization. Good risk mitigation finds a balance between the negative impact of countermeasures and controls and the benefit of risk reduction.
Mitigation Strategies: There are four common ways to reduce risk and they are;
Accept: Accept the risk and periodically re-assess.
Reduce: Reduce the risk by implementing controls.
Avoid: Avoid the risk by totally changing the approach.
Transfer: Transfer the risk to a third party like a service level agreement or insurance company.
A short-term strategy is to accept the risk necessitating the creation of contingency plans for that risk. Hiring specialists to perform critical tasks to reduce risk can be a good decision and yield greater results with less long term investment. 
Single Loss Expectancy(SLE) = Asset Value * Exposure Factor(EF).
Annual Loss Expectancy = Single Loss Expectancy(SLE) * Annualized Rate of Occurrence(ARO)
Layering: Layering is creating a barrier of multiple defenses that coordinate together to prevent attacks. A layered approach provides the most comprehensive protection. If cyber criminals penetrate one layer, they still have to contend with several more layers with each layer being more complicated than the previous. If there is only one defense in place to protect data and information, cyber criminals have only to get around that single defense. For example, an organization might store its top secret documents on a server in a building surrounded by an electronic fence.
Limiting: Limiting access to data and information reduces the possibility of a threat. An organization should restrict access so that users only have the level of access required to do their job. Technology-based solutions such as using file permissions are one way to limit access; an organization should also implement procedural measures. A procedure should be in place that prohibits an employee from removing sensitive documents from the premises.  For example, the people in the marketing department do not need access to payroll records to perform their jobs.
Diversity: If all of the protected layers were the same, it would not be very difficult for cyber criminals to conduct a successful attack. Therefore, the layers must be different. If cyber criminals penetrate one layer, the same technique will not work on all of the other layers. Breaching one layer of security does not compromise the whole system. An organization may use different encryption algorithms or authentication systems to protect data in different states. To accomplish the goal of diversity, organizations can use security products manufactured by different companies for multi factor authentication. For example, the server containing the top secret documents is in a locked room that requires a swipe card from one company and biometric authentication supplied by another company.
Obscurity: Obscuring information can also protect data and information. An organization should not reveal any information that cyber criminals can use to figure out what version of the operating system a server is running or the type of equipment it uses. For example, error messages should not contain any details that cyber criminals could use to determine what vulnerabilities are present. Concealing certain types of information makes it more difficult for cyber criminals to attack a system.
Simplicity: Complexity does not necessarily guarantee security. If an organization implements complex systems that are hard to understand and troubleshoot, it may actually backfire. If employees do not understand how to configure a complex solution properly, it may make it just as easy for cyber criminals to compromise those systems. To maintain availability, a security solution should be simple from the inside, but complex on the outside. 
Single Points Of Failure: Single points of failure are the weak links in the chain that can cause disruption of the organization's operations. They can be a special piece of hardware, a process, a specific piece of data, or even an essential utility.  The solution to a single point of failure is to modify the critical operation so that it does not rely on a single element. The organization can also build redundant components into the critical operation to take over the process should one of these points fail. 
N+1 Redundancy: N+1 redundancy means that the system design can withstand the loss of a component. The N refers to many different components that make up the data center including servers, power supplies, switches, and routers. The +1 is the additional component or system that is standing by ready to go if needed. An example of N+1 redundancy in a data center is a power generator that comes online when something happens to the main power source. Although an N+1 system contains redundant equipment, it is not a fully redundant system.
Redundant Array of Independent Disks(RAID): A redundant array of independent disks (RAID) combines multiple physical hard drives into a single logical unit to provide data redundancy and improve performance. RAID takes data that is normally stored on a single disk and spreads it out among several drives. If any single disk is lost, the user can recover data from the other disks where the data also resides. It also increase the speed of data recovery.
A RAID solution can be either hardware-based or software-based. A hardware-based solution requires a specialized hardware controller on the system that contains the RAID drives. The following terms describes how RAID stores data on the various disks;
Parity - Detects data errors.
Striping - Writes data across multiple drives.
Mirroring - Stores duplicate data on a second drive.
Spanning Tree Protocol(STP): The basic function of STP is to prevent loops on a network when switches interconnect via multiple paths. STP ensures that redundant physical links are loop-free. It ensures that there is only one logical path between all destinations on the network. STP intentionally blocks redundant paths that could cause a loop.  If a network cable or switch fails, STP recalculates the paths and unblocks the necessary ports to allow the redundant path to become active.
Router Redundancy: The default gateway is typically the router that provides devices access to the rest of the network or to the Internet. If there is only one router serving as the default gateway, it is a single point of failure. The organization can choose to install an additional standby router. The ability of a network to dynamically recover from the failure of a device acting as a default gateway is known as first-hop redundancy.
The following list defines the options available for router redundancy based on the protocol that defines communication between network devices:
Hot Standby Router Protocol (HSRP) - HSRP provides high network availability by providing first-hop routing redundancy. A group of routers use HSRP for selecting an active device and a standby device. In a group of device interfaces, the active device is the device that routes packets; the standby device is the device that takes over when the active device fails. The function of the HSRP standby router is to monitor the operational status of the HSRP group and to quickly assume packet-forwarding responsibility if the active router fails.
Virtual Router Redundancy Protocol (VRRP) - A VRRP router runs the VRRP protocol in conjunction with one or more other routers attached to a LAN. In a VRRP configuration, the elected router is the virtual router master, and the other routers act as backups, in case the virtual router master fails.
Gateway Load Balancing Protocol (GLBP) - GLBP protects data traffic from a failed router or circuit, like HSRP and VRRP, while also allowing load balancing (also called load sharing) between a group of redundant routers.
Location Redundancy: An organization may need to consider location redundancy depending on its needs. The following outlines three forms of location redundancy and they are;
Synchronous: Synchronizes both locations in real time, Requires high bandwidth,Locations must be close together to reduce latency.
Asynchronous Replication: Not synchronized in real time but close to it, Requires less bandwidth, Sites can be further apart because latency is less of an issue.
Point-in-time-Replication: Updates the backup data location periodically, Most bandwidth conservative because it does not require a constant connection.
The correct balance between cost and availability will determine the correct choice for an organization.
Resilient Design: Resiliency is the methods and configurations used to make a system or network tolerant of failure. For example, a network can have redundant links between switches running STP. Resilient design is more than just adding redundancy. It is critical to understand the business needs of the organization, and then incorporate redundancy to create a resilient network.
Application Resilience: Application resilience is the application’s ability to react to problems in one of its components while still functioning. Downtime is due to failures caused by application errors or infrastructure failures. It can also result to data corruption, equipment failures, application errors, and human errors. Application high availability is complex and costly.
Below is the three availability solutions to address application resilience and they are;
Fault Tolerant Hardware: A system designed by building multiples of all critical components into the same computer.
Cluster Architecture: A group of servers that act like a single system.
Backup and Restore: Copying files for the purpose of being able to restore them if data loss occurs. 
Interwork Operating System(IOS) Resilience: The Interwork Operating System (IOS) for Cisco routers and switches include a resilient configuration feature. It allows for faster recovery if someone maliciously or unintentionally reformats flash memory or erases the startup configuration file. The feature maintains a secure working copy of the router IOS image file and a copy of the running configuration file. The user cannot remove these secure files also known as the primary boot set.
Incident response is the procedures that an organization follows after an event occurs outside the normal range. A data breach releases information to an untrusted environment. A data breach can occur as the result of an accidental or intentional act. A data breach occurs anytime an unauthorized person copies, transmits, views, steals, or accesses sensitive information.
An organization needs to put together a Computer Security Incidence Response Team(CSIRT) to manage the response and their functions are; Maintains the incident response plan, Ensures its members are knowledgeable about the plan, Tests the plan, Gets management’s approval of the plan.
Detection and Analysis: Proper detection includes how the incident occurred, what data it involved, and what systems it involved. Notification of the breach goes out to senior management and managers responsible for the data and systems to involve them in the remediation and repair. Incident analysis helps to identify the source, extent, impact, and details of a data breach.
Detection and Analysis includes; Alerts and Notifications, Monitoring and follow-up. The organization may need to decide if it needs to call in a team of experts to conduct the forensics investigation.
Containment, Eradication and Recovery: Containment efforts include the immediate actions performed such as disconnecting a system from the network to stop the information leak. After identifying the breach, the organization needs to contain and eradicate it. This may require additional downtime for systems. The recovery stage includes the actions that the organization needs to take in order to resolve the breach and restore the systems involved. After remediation, the organization needs to restore all systems to their original state before the breach.
Post-Incident Follow-Up: After restoring all operations to a normal state, the organization should look at the cause of the incident and ask the following questions: What actions will prevent the incident from reoccurring?
What preventive measures need strengthening?
How can it improve system monitoring?
How can it minimize downtime during the containment, eradication, and recovery phases?
How can management minimize the impact to the business? 
NB: The Incidence Response Phases are in these order; Preparation, Detection and Analysis, Containment, Eradication, and Recovery, Post-Incident Follow-up .
Network Admission Control(NAC): The purpose of Network Admission Control (NAC) allows authorized users with compliant systems access to the network. A compliant system meets all of the policy requirements of the organization. For example, a laptop that is part of a home wireless network may not be able to connect remotely to the corporate network.
A NAC framework can use the existing network infrastructure and third-party software to enforce the security policy compliance for all endpoints. Alternately, a NAC appliance controls network access, evaluates compliance, and enforces security policy. Common NAC systems checks include: Updated Virus Detection, Operating Systems Patches and Updates, Complex Password Enforcement. 
Intrusion Detection System(IDS): Intrusion Detection Systems (IDSs) passively monitor the traffic on a network. Passive means that the IDS monitors and reports on traffic. It does not take any action. This is the definition of operating in promiscuous mode. IDS device is physically positioned in the network so that traffic must be mirrored in order to reach it. Network traffic does not pass through the IDS unless it is mirrored.
The advantage of operating with a copy of the traffic is that the IDS does not negatively affect the packet flow of the forwarded traffic. The disadvantage of operating on a copy of the traffic is that the IDS cannot stop malicious single-packet attacks from reaching the target before responding to the attack. An IDS often requires assistance from other networking devices, such as routers and firewalls, to respond to an attack. A better solution is to use a device that can immediately detect and stop an attack. An Intrusion Prevention System (IPS) performs this function.
Intrusion Prevention Systems(IPS): An IPS builds upon IDS technology. However, an IPS device operates in inline mode. This means that all incoming and outgoing traffic must flow through it for processing. An IPS does not allow packets to enter the trusted side of the network unless it has analyzed the packets. It can detect and immediately address a network problem. When a packet comes in through an interface on an IPS, the outbound or trusted interface does not receive that packet until the IPS analyzes the packet.
The advantage of operating in inline mode is that the IPS can stop single-packet attacks from reaching the target system. The disadvantage is that a poorly configured IPS can negatively affect the packet flow of the forwarded traffic. The biggest difference between IDS and IPS is that an IPS responds immediately and does not allow any malicious traffic to pass, whereas an IDS allows malicious traffic to pass before addressing the problem.
NetFlow and IP Flow Information Export(IPFIX): NetFlow is a Cisco IOS technology that provides statistics on packets flowing through a Cisco router or multilayer switch. NetFlow is the standard for collecting operational data from networks. IPFIX is a standard format for exporting router-based information about network traffic flows to data collection devices. IPFIX works on routers and management applications that support the protocol.
Applications that support IPFIX can display statistics from any router that supports the standard. Collecting, storing, and analyzing the aggregated information provided by IPFIX supported devices provides the following benefits:
Secures the network against internal and external threats.
Troubleshoots network failures quickly and precisely.
Analyzes network flows for capacity planning.
Advanced Threat Intelligence: Advanced threat intelligence can help organizations detect attacks during one of the stages of the cyberattack and sometimes before with the right information. Advanced threat intelligence is a type of event or profile data that can contribute to security monitoring and response. As the cyber criminals become more sophisticated, it is important to understand the malware maneuvers. With improved visibility into attack methodologies, an organization can respond more quickly to incidents.
Organizers may be able to detect indicators of attack in its logs and system reports for the following security alerts: Account lockouts, All database events, Asset creation and deletion, Configuration modification to systems.
Disasters and Types: A disaster includes any natural or human-caused event that damages assets or property and impairs the ability for the organization to continue operating. Types of Disasters includes;
Natural Disasters: These disasters fall into the following categories;
Geological disasters include earthquakes, landslides, volcanoes, and tsunamis
Meteorological disasters include hurricanes, tornadoes, snow storms, lightning, and hail
Health disasters include widespread illnesses, quarantines, and pandemics
Miscellaneous disasters include fires, floods, solar storms, and avalanches
Human-Caused Disasters involve people or organization and they fall into the following categories:
Labor events include strikes, walkouts, and slowdowns
Social-political events include vandalism, blockades, protests, sabotage, terrorism, and war
Materials events include hazardous spills and fires
Utilities disruptions include power failures, communication outages, fuel shortages, and radioactive fallout. 
Disaster Recovery Plan: An organization puts its disaster recovery plan (DRP) into action while the disaster is ongoing and employees are scrambling to ensure critical systems are online. The DRP includes the activities the organization takes to assess, salvage, repair, and restore damaged facilities or assets. A DRP needs to identify which processes in the organization are the most critical. During the recovery process, the organization restores its mission critical systems first. 
Implementing Disaster Recovery Controls: Disaster recovery controls minimize the effects of a disaster to ensure that resources and business processes can resume operation. There are three types of IT disaster recovery controls and they are;
Preventative measures include controls that prevent a disaster from occurring. These measures seek to identify risks and they are; Keeping data backed up, Keeping data backups off-site, Using surge protectors, Installing generators.
Detective measures include controls that discover unwanted events. These measures uncover new potential threats and they are; Using up-to-date antivirus software, Installing server and network monitoring software. 
Corrective measures include controls that restore the system after a disaster or an event. An example is keeping critical documents in the disaster recovery plan. 
A business continuity plan is a broader plan than a DRP because it includes getting critical systems to another location while repair of the original facility is under way. Personnel continue to perform all business processes in an alternate manner until normal operations resume. It is important for companies to have plans in place that ensure business continuity regardless of what may occur. Business continuity is one of the most important concepts in computer security. Availability ensures that the resources required to keep the organization going will continue to be available to the personnel and the systems that rely on them. 
Business continuity controls are more than just backing up data and providing redundant hardware. Organizations need employees to properly configure and operate systems. An organization should look at the following: Getting the right people to the right places, Documenting configurations, Establishing alternate communications channels for both voice and data, Providing power, Identifying all dependencies for applications and processes so that they are properly understood, Understanding how to carry out automated tasks manually. 
Business Continuity Best Practices: The National Institute of Standards and Technology (NIST) developed the following best practices and they include;
Write a policy that provided guidance to develop the business continuity plan and assigns roles to carry out the tasks.
Identify critical systems and processes and prioritize them based on necessity.
Identify vulnerabilities, threats, and calculate risks.
Identify and implement controls and countermeasures to reduce risk.
Devise methods to bring back critical systems quickly.
Write procedures to keep the organization functioning in a chaotic state.
Test the plan.
Update the plan regularly.    